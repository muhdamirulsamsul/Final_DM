{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WQD7005: Data Mining ###\n",
    "\n",
    "FINAL EXAMINATION\n",
    "\n",
    "------------------------------------------\n",
    "Name: Muhammad Amirul bin Samsul Bahar<br>\n",
    "ID: 17202062 (New)/WQD190041 (Old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1:\n",
    "----------------------------\n",
    "You are required to make a user-agent that will crawll WWW (your familiar domain) to produce dataset of a particulat website.\n",
    "* the web site can be as simple as a list of webpages and what other pages they link to\n",
    "* the output does not need to be in XHTML (or HTML) form a multi-stage approach (e.g. produce the xhtml or html  in csv format)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the libraries needed to crawl data from website is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing HTML to BeautifulSoup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "    'Accept-Encoding': 'none',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "url = \"https://gist.github.com/curran/a08a1080b88344b0c8a7\"\n",
    "req = urllib.request.Request(url, headers=header)\n",
    "html = urlopen(req).read()\n",
    "soup_html = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a glimpse on the html body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body class=\"logged-out env-production min-width-lg\">\n",
       "<div class=\"position-relative js-header-wrapper\">\n",
       "<a class=\"px-2 py-4 bg-blue text-white show-on-focus js-skip-to-content\" href=\"#start-of-content\">Skip to content</a>\n",
       "<span class=\"Progress progress-pjax-loader position-fixed width-full js-pjax-loader-bar\">\n",
       "<span class=\"progress-pjax-loader-bar top-0 left-0\" style=\"width: 0%;\"></span>\n",
       "</span>\n",
       "<div class=\"Header\" role=\"banner\">\n",
       "<div class=\"Header-item\">\n",
       "<a aria-label=\"Gist Homepage \" class=\"Header-link\" data-hotkey=\"g d\" href=\"/\">\n",
       "<svg aria-hidden=\"true\" class=\"octicon octicon-mark-github v-align-middle d-none\" height=\"24\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"24\"><path d=\"M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z\" fill-rule=\"evenodd\"></path></svg>\n",
       "<svg aria-hidden=\"true\" class=\"octicon octicon-logo-github v-align-middle\" height=\"24\" version=\"1.1\" viewbox=\"0 0 45 16\" width=\"67\"><path d=\"M18.53 12.03h-.02c.009 0 .015.01.024.011h.006l-.01-.01zm.004.011c-.093.001-.327.05-.574.05-.78 0-1.05-.36-1.05-.83V8.13h1.59c.09 0 .16-.08.16-.19v-1.7c0-.09-.08-.17-.16-.17h-1.59V3.96c0-.08-.05-.13-.14-.13h-2.16c-.09 0-.14.05-.14.13v2.17s-1.09.27-1.16.28c-.08.02-.13.09-.13.17v1.36c0 .11.08.19.17.19h1.11v3.28c0 2.44 1.7 2.69 2.86 2.69.53 0 1.17-.17 1.27-.22.06-.02.09-.09.09-.16v-1.5a.177.177 0 00-.146-.18zM42.23 9.84c0-1.81-.73-2.05-1.5-1.97-.6.04-1.08.34-1.08.34v3.52s.49.34 1.22.36c1.03.03 1.36-.34 1.36-2.25zm2.43-.16c0 3.43-1.11 4.41-3.05 4.41-1.64 0-2.52-.83-2.52-.83s-.04.46-.09.52c-.03.06-.08.08-.14.08h-1.48c-.1 0-.19-.08-.19-.17l.02-11.11c0-.09.08-.17.17-.17h2.13c.09 0 .17.08.17.17v3.77s.82-.53 2.02-.53l-.01-.02c1.2 0 2.97.45 2.97 3.88zm-8.72-3.61h-2.1c-.11 0-.17.08-.17.19v5.44s-.55.39-1.3.39-.97-.34-.97-1.09V6.25c0-.09-.08-.17-.17-.17h-2.14c-.09 0-.17.08-.17.17v5.11c0 2.2 1.23 2.75 2.92 2.75 1.39 0 2.52-.77 2.52-.77s.05.39.08.45c.02.05.09.09.16.09h1.34c.11 0 .17-.08.17-.17l.02-7.47c0-.09-.08-.17-.19-.17zm-23.7-.01h-2.13c-.09 0-.17.09-.17.2v7.34c0 .2.13.27.3.27h1.92c.2 0 .25-.09.25-.27V6.23c0-.09-.08-.17-.17-.17zm-1.05-3.38c-.77 0-1.38.61-1.38 1.38 0 .77.61 1.38 1.38 1.38.75 0 1.36-.61 1.36-1.38 0-.77-.61-1.38-1.36-1.38zm16.49-.25h-2.11c-.09 0-.17.08-.17.17v4.09h-3.31V2.6c0-.09-.08-.17-.17-.17h-2.13c-.09 0-.17.08-.17.17v11.11c0 .09.09.17.17.17h2.13c.09 0 .17-.08.17-.17V8.96h3.31l-.02 4.75c0 .09.08.17.17.17h2.13c.09 0 .17-.08.17-.17V2.6c0-.09-.08-.17-.17-.17zM8.81 7.35v5.74c0 .04-.01.11-.06.13 0 0-1.25.89-3.31.89-2.49 0-5.44-.78-5.44-5.92S2.58 1.99 5.1 2c2.18 0 3.06.49 3.2.58.04.05.06.09.06.14L7.94 4.5c0 .09-.09.2-.2.17-.36-.11-.9-.33-2.17-.33-1.47 0-3.05.42-3.05 3.73s1.5 3.7 2.58 3.7c.92 0 1.25-.11 1.25-.11v-2.3H4.88c-.11 0-.19-.08-.19-.17V7.35c0-.09.08-.17.19-.17h3.74c.11 0 .19.08.19.17z\" fill-rule=\"evenodd\"></path></svg>\n",
       "<svg aria-hidden=\"true\" class=\"octicon octicon-logo-gist v-align-middle\" height=\"24\" version=\"1.1\" viewbox=\"0 0 25 16\" width=\"37\"><path d=\"M4.7 8.73h2.45v4.02c-.55.27-1.64.34-2.53.34-2.56 0-3.47-2.2-3.47-5.05 0-2.85.91-5.06 3.48-5.06 1.28 0 2.06.23 3.28.73V2.66C7.27 2.33 6.25 2 4.63 2 1.13 2 0 4.69 0 8.03c0 3.34 1.11 6.03 4.63 6.03 1.64 0 2.81-.27 3.59-.64V7.73H4.7v1zm6.39 3.72V6.06h-1.05v6.28c0 1.25.58 1.72 1.72 1.72v-.89c-.48 0-.67-.16-.67-.7v-.02zm.25-8.72c0-.44-.33-.78-.78-.78s-.77.34-.77.78.33.78.77.78.78-.34.78-.78zm4.34 5.69c-1.5-.13-1.78-.48-1.78-1.17 0-.77.33-1.34 1.88-1.34 1.05 0 1.66.16 2.27.36v-.94c-.69-.3-1.52-.39-2.25-.39-2.2 0-2.92 1.2-2.92 2.31 0 1.08.47 1.88 2.73 2.08 1.55.13 1.77.63 1.77 1.34 0 .73-.44 1.42-2.06 1.42-1.11 0-1.86-.19-2.33-.36v.94c.5.2 1.58.39 2.33.39 2.38 0 3.14-1.2 3.14-2.41 0-1.28-.53-2.03-2.75-2.23h-.03zm8.58-2.47v-.86h-2.42v-2.5l-1.08.31v2.11l-1.56.44v.48h1.56v5c0 1.53 1.19 2.13 2.5 2.13.19 0 .52-.02.69-.05v-.89c-.19.03-.41.03-.61.03-.97 0-1.5-.39-1.5-1.34V6.94h2.42v.02-.01z\" fill-rule=\"evenodd\"></path></svg>\n",
       "</a>\n",
       "</div>\n",
       "<div class=\"Header-item Header-item--full js-site-search\">\n",
       "<div class=\"header-search header-search-current mr-3\">\n",
       "<!-- '\"` --><!-- </textarea></xmp> --></div></div></div></div></body>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_html.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from the Beautiful Soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = soup_html.find(id=\"file-iris-csv\").find_all(\"tr\")\n",
    "\n",
    "# Columns of the dataset\n",
    "head_col = data[0].text.split()\n",
    "\n",
    "# Records of the dataset\n",
    "sepal_length = []\n",
    "sepal_width = []\n",
    "petal_length = []\n",
    "petal_width = []\n",
    "species = []\n",
    "\n",
    "for i in data[1:]:\n",
    "    a = i.findAll('td')\n",
    "    sepal_length.append(a[1].text.strip())\n",
    "    sepal_width.append(a[2].text.strip())\n",
    "    petal_length.append(a[3].text.strip())\n",
    "    petal_width.append(a[4].text.strip())\n",
    "    species.append(a[5].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the columns:\n",
      "sepal_length\n",
      "sepal_width\n",
      "petal_length\n",
      "petal_width\n",
      "species\n"
     ]
    }
   ],
   "source": [
    "print(\"The name of the columns:\")\n",
    "for i in head_col:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The records of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 records for sepal_length:\n",
      "5.1\n",
      "4.9\n",
      "4.7\n",
      "4.6\n",
      "5.0\n",
      "\n",
      "\n",
      "The first 5 records for sepal_width:\n",
      "3.5\n",
      "3.0\n",
      "3.2\n",
      "3.1\n",
      "3.6\n",
      "\n",
      "\n",
      "The first 5 records for petal_length:\n",
      "1.4\n",
      "1.4\n",
      "1.3\n",
      "1.5\n",
      "1.4\n",
      "\n",
      "\n",
      "The first 5 records for petal_width:\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "record = [sepal_length, sepal_width, petal_length, petal_width]\n",
    "k = 0\n",
    "for i in record:\n",
    "    print(\"The first 5 records for \"+head_col[k]+\":\")\n",
    "    for j in i[:5]:\n",
    "        print(j)\n",
    "    print(\"\\n\")\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a DataFrame object from the estracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, ...\n",
       "1  [3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, ...\n",
       "2  [1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, ...\n",
       "3  [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, ..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "------------------------------------------------------\n",
    "Draw snowflake schema diagram for the above dataset. Justify your attributes to be selected in the respective dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3:\n",
    "---------------------\n",
    "You are required to write code to  create a decision tree (DT) model using the above dataset (Question 1). In order to achieve the task, you are going to cover the following steps:\n",
    "* Importing required libraries\n",
    "* Loading data\n",
    "* Feature selection\n",
    "* Splitting data\n",
    "* Building decision tree model\n",
    "* Evaluating model\n",
    "* Visualizing decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4:\n",
    "------------\n",
    "You are required to write code to  find frequent itemsets using the above dataset (Question 1). In order to achieve the task, you are going to cover the following steps:\n",
    "* Importing required libraries\n",
    "* Creating a list from dataset (Question 1)\n",
    "* Convert list to dataframe with boolean values\n",
    "* Find frequently occuring itemsets using Apriori algorithm\n",
    "* Find frequently occuring itemsets using F-P growth\n",
    "* Mine the association rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5:\n",
    "-----------------\n",
    "You are required to write code to implement either time-series clustering or density-based clustering model using the above dataset (Question 1). If you select density-based clustering approach to achieve the task, you are going to cover the following steps:\n",
    "* Importing required libraries\n",
    "* Load the dataset (Question 1) into a DataFrame object\n",
    "* Visualize the data, use only two of these attributes at a time\n",
    "* You may need to normalize the aatributes if necessary\n",
    "* Show possitive correlation between attributes if necessary\n",
    "* Consruct a density-based clustering model and extract cluster labels and outliers to plot your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
